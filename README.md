# Create a local GPU powered inference from a LLaMa model.

